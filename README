This is a unsupported rapid prototype of a clustered system build with Lucy


The system should work by distributing a Lucy index on many nodes. 
The main difference between differences in the interface a user will see
is.

1. the enforcement of a primary_key in the schema.
2. you can't use delete_by_query so deletes need to be 
   done with the primary_key
3. must know how to reach 1+ cluster_server.



The Basic Idea.

Create N virtual shards (Standard Lucy Indexes). Distribute them over Y nodes (physical servers).

So lets say N=30, Y=3. We would place 10 shards on each of the 3 boxes. Then performer Local 
muti-searches on the 10 indexes (async) sending the results for all 10 shards back as a single result 
for each of the 3 nodes (async). I'm looking to see how fast i can do the 10 local searches and sync 
them with the other 2 nodes.. 



\bin\
  cluster_server.pl (1 per server) 
    This guy spawns cluster_search_node and cluster_write_node.

  cluster_write_node.pl (N per cluster_node)
    This guy does blocking writes into indexes at the cluster_servers request.
  
  cluster_search_node.pl  (~1 per-core)
    This guy is our async muti-searcher it spawns and controls cluster_searcher.
  
  cluster_searcher.pl (N per cluster_node)
    This guy does blocking searches on the indexes at the cluster_nodes request
    (the index being muti-searched)

